{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563d5782-9902-449b-9aa3-ced1d29ca0d3",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/code/julqka/gilmore-girls-network-analysis?select=Gilmore_Girls_Lines.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91a622a-5ac1-4c0a-b8e6-37460126d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d0da10-8f3f-4cdd-bdd8-ad1301f2fcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/asthapuri/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/asthapuri/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/asthapuri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/asthapuri/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('punkt_tab')  # Download the sentence tokenizer\n",
    "nltk.download('wordnet')  # Download WordNet, required for semantic analysis for lemmatization\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('omw-1.4')  # Download the Open Multilingual Wordnet corpus for multilingual semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baba4f75-8d47-4331-8e9a-2cdcc34aa350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Gilmore_Girls_Lines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950000ee-9b7b-490d-a271-ef2800ae2703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>Please, Luke. Please, please, please.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Luke</td>\n",
       "      <td>How many cups have you had this morning?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>None.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Luke</td>\n",
       "      <td>Plus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>Five, but yours is better.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Character                                      Line  Season\n",
       "0           0   Lorelai     Please, Luke. Please, please, please.       1\n",
       "1           1      Luke  How many cups have you had this morning?       1\n",
       "2           2   Lorelai                                     None.       1\n",
       "3           3      Luke                                   Plus...       1\n",
       "4           4   Lorelai                Five, but yours is better.       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce8c411-4ccd-464f-b2e4-c8432eecf6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lorelai = df[df['Character']=='Lorelai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d57e262e-adb2-454c-a389-67e60c06a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>Please, Luke. Please, please, please.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>None.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>Five, but yours is better.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>Yes, I do.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Lorelai</td>\n",
       "      <td>Angel. You've got wings, baby.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Character                                   Line  Season\n",
       "0           0   Lorelai  Please, Luke. Please, please, please.       1\n",
       "2           2   Lorelai                                  None.       1\n",
       "4           4   Lorelai             Five, but yours is better.       1\n",
       "6           6   Lorelai                             Yes, I do.       1\n",
       "8           8   Lorelai         Angel. You've got wings, baby.       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorelai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358b1159-1ca0-4257-96b2-3c7958dc141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lorelai_dialog = ' '.join(lorelai['Line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a3017b-2a1e-4f56-892e-512cb230bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rory = df[df['Character']=='Rory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdfbae37-3948-4373-95df-34680e75633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Rory</td>\n",
       "      <td>Hey. It's freezing.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Rory</td>\n",
       "      <td>Lip gloss.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Rory</td>\n",
       "      <td>Anything in there not resembling a breakfast c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Rory</td>\n",
       "      <td>God, RuPaul doesn't need this much makeup.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Rory</td>\n",
       "      <td>I'm sorry. I lost my Macy Gray CD and I need c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Character                                               Line  \\\n",
       "30          30      Rory                                Hey. It's freezing.   \n",
       "32          32      Rory                                         Lip gloss.   \n",
       "35          35      Rory  Anything in there not resembling a breakfast c...   \n",
       "38          38      Rory         God, RuPaul doesn't need this much makeup.   \n",
       "40          40      Rory  I'm sorry. I lost my Macy Gray CD and I need c...   \n",
       "\n",
       "    Season  \n",
       "30       1  \n",
       "32       1  \n",
       "35       1  \n",
       "38       1  \n",
       "40       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5f0f15-570a-430c-adbc-68b502f7cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rory_dialog = ' '.join(rory['Line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3481876-0cba-4f3d-b384-1cf036920103",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [lorelai_dialog, rory_dialog]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45843ab5-c4ee-45bc-91c8-4735528dc8f4",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c6fa45-4ea4-46ce-bcf1-4fca68dcba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_docs = []\n",
    "for doc in corpus:\n",
    "  tokens = word_tokenize(doc)\n",
    "  tokenized_docs.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bc5a1-06f7-4f0b-bc5a-2dca45eddab7",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd502803-d8f7-48c5-a45e-7dbdd4a71f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens to lowercase\n",
    "lowercased_docs = []\n",
    "for tokens in tokenized_docs:\n",
    "    lowercased_tokens = [token.lower() for token in tokens]\n",
    "    lowercased_docs.append(lowercased_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1320e4-aa8e-4417-a011-247988b63555",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee726ef-a92f-4788-a4d2-f8bb9166cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "no_punctuation_docs = []\n",
    "for tokens in lowercased_docs:\n",
    "    filtered_tokens = [token for token in tokens if token.isalpha()]  # Remove punctuation\n",
    "    no_punctuation_docs.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1881f7-839b-4a22-8d59-3b4b04a4ae70",
   "metadata": {},
   "source": [
    "### Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ffed23-dff1-4e1f-afd1-3cffc41ad6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words Removal\n",
    "from nltk.corpus import stopwords\n",
    "# Get the English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "no_stopwords_docs = []\n",
    "for tokens in no_punctuation_docs:\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    no_stopwords_docs.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff97c5c2-9055-4588-a7b6-18ace997820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'also' to the set of stopwords\n",
    "stop_words.add('also')\n",
    "\n",
    "# Remove stopwords again, now including 'also'\n",
    "no_stopwords_including_also_docs = []\n",
    "for tokens in no_stopwords_docs:  # We'll start from the already stopword-removed docs\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    no_stopwords_including_also_docs.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b149c4-c2af-41c3-baaf-7459b93d8564",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2690c604-0997-4a9a-b97f-e4ca081395d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Apply stemming to the documents\n",
    "stemmed_docs = []\n",
    "for tokens in no_stopwords_including_also_docs:\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    stemmed_docs.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d35fc3-c233-4407-bef6-92f620023a6c",
   "metadata": {},
   "source": [
    "### Advantages-\n",
    "- Faster and simpler: It's computationally less expensive than other techniques like lemmatization.\n",
    "- Reduces vocabulary size: By grouping words with similar stems, it helps manage large datasets more efficiently.\n",
    "\n",
    "### Disadvantages\n",
    "- The most prevelant one is Oversimplification: Can lead to incorrect stems, like transforming \"cars\" and \"care\" into the same stem \"car\".\n",
    "- Meaning loss: Removing suffixes can alter the word's meaning, causing confusion.\n",
    "- Not context-aware: Doesn't consider different grammatical roles a word can play within a sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e2bf8-1f3c-425e-85e2-50b7dc27192a",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70301ce6-5da7-493f-bf7b-26b1940814eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b6cafd9-89cd-4136-87fb-dd73bee0e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model with lemmatization capabilities\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Apply lemmatization using spaCy\n",
    "spacy_lemmatized_docs = []\n",
    "for doc in no_stopwords_including_also_docs:\n",
    "    # Process the document using spaCy\n",
    "    spacy_doc = nlp(' '.join(doc))\n",
    "    # Extract lemmatized tokens\n",
    "    spacy_lemmatized_tokens = [token.lemma_ for token in spacy_doc]\n",
    "    spacy_lemmatized_docs.append(spacy_lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac61df-9bae-490a-a648-ee897180f23f",
   "metadata": {},
   "source": [
    "### Advantages:\n",
    "- Preserves Meaning: Lemmatization aims to find the dictionary form of a word, resulting in a base form that still retains its meaning. Stemming, on the other hand, simply chops off suffixes without considering context, potentially leading to meaningless stems like \"lov\" for \"loved\" or \"walk\" for \"walker.\"\n",
    "- More Accurate: Lemmatization utilizes dictionaries and linguistic information to choose the correct base form based on the word's part-of-speech and context. Stemming is rule-based and can produce ambiguous results, especially for words with multiple meanings or non-standard forms.\n",
    "- Improves downstream tasks: The accuracy of lemmatization leads to better performance in tasks like information retrieval, text classification, and sentiment analysis because words with similar meanings are grouped correctly. Stemming's less accurate results can negatively impact these tasks.\n",
    "\n",
    "### Disadvantages:\n",
    "- Slower and computationally expensive: Lemmatization requires accessing dictionaries and performing more complex analysis, making it slower than stemming, which uses simple rules.\n",
    "- Not always perfect: Even lemmatization can make mistakes in complex cases or due to limitations in dictionaries and linguistic models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcc686-beac-47f6-a97d-afe0abd24050",
   "metadata": {},
   "source": [
    "### Vocabulary Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "331d2f08-ec7e-4da9-8818-48f714276a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty set to store the vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "# Iterate over each document and add each unique word to the vocabulary set\n",
    "for doc in spacy_lemmatized_docs:\n",
    "    for token in doc:\n",
    "        vocabulary.add(token)\n",
    "\n",
    "# Convert the set to a sorted list if you want the vocabulary to be ordered\n",
    "vocabulary = sorted(list(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad660c-97e3-4fc4-8ff2-c4d10c88fe05",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dec7e274-8f4e-4163-8140-dbfa2d7e80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary library\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af6c22c9-43a7-4c9b-9572-5bc65f521455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lemmatized documents back into string format for vectorization\n",
    "documents = [\" \".join(doc) for doc in spacy_lemmatized_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e5c81-5a40-43c0-b1df-44c9e98c40aa",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4784b490-fc7a-4e94-8e18-372b93e792d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_ohe = CountVectorizer(vocabulary=vocabulary, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a9d5bf2-995e-44e4-a440-fffcd8e82b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['aa' 'aaaah' 'aaagh' ... 'zurich' 'zydeco' 'zzz']\n",
      "Document-Term Matrix Shape: (2, 13298)\n",
      "Frequency Counts:\n",
      " [[0 1 1 ... 0 1 1]\n",
      " [1 0 0 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the documents\n",
    "X = vectorizer_ohe.fit_transform(documents)\n",
    " \n",
    "# Get the feature names (vocabulary)\n",
    "feature_names = vectorizer_ohe.get_feature_names_out()\n",
    "\n",
    "# Display the feature names and the shape of the document-term matrix\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"Document-Term Matrix Shape:\", X.shape)\n",
    "\n",
    "# If you want to see the frequency count of each word in the document\n",
    "frequency_counts = X.toarray()\n",
    "print(\"Frequency Counts:\\n\", frequency_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d7952f6-d2ff-4b3e-a967-3b0cc2a001ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaagh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aaaww</th>\n",
       "      <th>aah</th>\n",
       "      <th>aahh</th>\n",
       "      <th>aalgonquin</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zsa</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 13298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  aa aaaah aaagh aaah aaaww aah aahh aalgonquin aaron ab  ... zombie zone zoo  \\\n",
       "0  0     1     1    1     1   1    1          1     1  1  ...      1    1   1   \n",
       "1  1     0     0    0     0   1    0          0     0  0  ...      0    1   1   \n",
       "\n",
       "  zoom zsa zucchini zucker zurich zydeco zzz  \n",
       "0    1   1        1      1      0      1   1  \n",
       "1    0   1        0      0      1      1   0  \n",
       "\n",
       "[2 rows x 13298 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=[feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f311073-68ba-4333-99e2-da1b1f0af5ab",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd9de38d-8ba5-4e9f-84a4-a22ea557e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer(vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28944942-1177-4cab-aad7-da37eb7c786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['aa' 'aaaah' 'aaagh' ... 'zurich' 'zydeco' 'zzz']\n",
      "Document-Term Matrix Shape: (2, 13298)\n",
      "Frequency Counts:\n",
      " [[0 1 1 ... 0 1 1]\n",
      " [1 0 0 ... 2 3 0]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the documents\n",
    "X = count_vectorizer.fit_transform(documents)\n",
    " \n",
    "# Get the feature names (vocabulary)\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the feature names and the shape of the document-term matrix\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"Document-Term Matrix Shape:\", X.shape)\n",
    "\n",
    "# If you want to see the frequency count of each word in the document\n",
    "frequency_counts = X.toarray()\n",
    "print(\"Frequency Counts:\\n\", frequency_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a6b21d8-7fb3-46bf-a415-2fa2908a50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaagh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aaaww</th>\n",
       "      <th>aah</th>\n",
       "      <th>aahh</th>\n",
       "      <th>aalgonquin</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zsa</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 13298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  aa aaaah aaagh aaah aaaww aah aahh aalgonquin aaron ab  ... zombie zone zoo  \\\n",
       "0  0     1     1    1     1  10    1          1     1  2  ...      1    5   2   \n",
       "1  1     0     0    0     0   5    0          0     0  0  ...      0    6   2   \n",
       "\n",
       "  zoom zsa zucchini zucker zurich zydeco zzz  \n",
       "0    1   2       13      1      0      1   1  \n",
       "1    0   2        0      0      2      3   0  \n",
       "\n",
       "[2 rows x 13298 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=[feature_names])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
